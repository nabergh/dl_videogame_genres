{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable as V\n",
    "import torchvision.transforms as transforms\n",
    "from torch.nn import functional as F\n",
    "from PIL import Image\n",
    "from PIL.ImageFilter import GaussianBlur\n",
    "from genre_classifier import GenreClassifier\n",
    "topil = transforms.ToPILImage()\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pickle.load(open('results/test_preds_3bn.p', 'rb')).data\n",
    "labels = pickle.load(open('results/test_labels_3bn.p', 'rb')).data\n",
    "ids = pickle.load(open('results/test_ids_3bn.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_preds = preds.clone()\n",
    "for genre_ind in range(preds.size(1)):\n",
    "    genre_labs = labels[:,genre_ind].clone().numpy()\n",
    "    np.random.shuffle(genre_labs)\n",
    "    rand_preds[:,genre_ind] = torch.FloatTensor(genre_labs)\n",
    "\n",
    "bce = torch.nn.BCELoss()\n",
    "rand_test_loss = bce(V(rand_preds), V(labels))\n",
    "print(rand_test_loss.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_preds = F.threshold(preds, 0.5, 0)\n",
    "thresh_preds = -1 * (F.threshold(-1 * thresh_preds, -0.5, -1))\n",
    "labels.eq(thresh_preds.data).sum() / (4395 * 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genre_ids = {'Action': 0,\n",
    "    'Adventure': 1,\n",
    "    'Arcade': 2,\n",
    "    'Compilation': 3,\n",
    "    'Driving_Racing': 4,\n",
    "    'Educational': 5,\n",
    "    'Fighting': 6,\n",
    "    'Music_Rhythm': 7,\n",
    "    'Platformer': 8,\n",
    "    'Puzzle': 9,\n",
    "    'Role-Playing': 10,\n",
    "    'Shooter': 11,\n",
    "    'Simulation': 12,\n",
    "    'Sports': 13,\n",
    "    'Strategy': 14,\n",
    "    'Trivia_Board Game': 15}\n",
    "genres = {}\n",
    "for key, val in genre_ids.items():\n",
    "    genres[val] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = preds.numpy()\n",
    "labels = labels.numpy()\n",
    "ids = ids.numpy().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre = 15\n",
    "precision, recall, _ = precision_recall_curve(labels[:,genre], preds[:,genre])\n",
    "ap = average_precision_score(labels[:,genre], preds[:,genre])\n",
    "\n",
    "lw = 2\n",
    "plt.clf()\n",
    "plt.plot(recall, precision, lw=lw, color='navy',\n",
    "         label='Precision-Recall curve')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title(genres[genre] + ': AP={0:0.2f}'.format(ap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_img(path):\n",
    "    img = Image.open(path).convert('RGB')\n",
    "    smaller = min(img.size[0], img.size[1])\n",
    "    larger = max(img.size[0], img.size[1])\n",
    "    pad_width = larger - smaller\n",
    "    new_im = None\n",
    "    if img.size[0] == smaller:\n",
    "        new_size = (pad_width + img.size[0], img.size[1])\n",
    "        new_im = Image.new(\"RGB\", new_size)\n",
    "        new_im.paste(img, (pad_width // 2, 0))\n",
    "    else:\n",
    "        new_size = (img.size[0], pad_width + img.size[1])\n",
    "        new_im = Image.new(\"RGB\", new_size)\n",
    "        new_im.paste(img, (0, pad_width // 2))\n",
    "    img = new_im\n",
    "    im_trans = transforms.Compose([transforms.Scale(256),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    img = im_trans(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_preds = np.zeros((16,5))\n",
    "top_labels = np.zeros((16,5))\n",
    "top_genres = np.zeros((16,5,16))\n",
    "top_ids = np.zeros((16,5)).astype(int)\n",
    "for genre, gid in genre_ids.items():\n",
    "    order = np.argsort(preds[:,gid])[::-1]\n",
    "    top_preds[gid] = preds[order[:5],gid]\n",
    "    top_labels[gid] = labels[order[:5],gid]\n",
    "    top_genres[gid] = labels[order[:5]]\n",
    "    top_ids[gid] = np.copy(ids[order[:5]]).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tensor = get_img('scraped_imgs/' + str(top_ids[0][0]) + '.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dtype = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n",
    "\n",
    "model = GenreClassifier(dtype, 16)\n",
    "model.load_state_dict(pickle.load(open('models/genre_class_3bn_dropoutconv_ep_29.p', 'rb')))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gid in range(16):\n",
    "# for gid in range(4,5):\n",
    "    path = 'scraped_imgs/'\n",
    "    for i in range(5):\n",
    "#     for i in range(3):\n",
    "        img_tensor = get_img(path + str(top_ids[gid][i]) + '.jpeg').type(dtype)\n",
    "        invar = V(img_tensor.unsqueeze(0), requires_grad=True)\n",
    "\n",
    "        prediction = model(invar)\n",
    "\n",
    "        loss = bce(prediction, V(torch.from_numpy(top_genres[gid][i])).type(dtype))\n",
    "        loss.backward()\n",
    "\n",
    "        grad_img = invar.grad.data.squeeze(0).cpu()\n",
    "        mean = torch.mean(torch.max(grad_img, torch.zeros(grad_img.size())))\n",
    "        pos_grad_img = F.threshold(V(torch.max(grad_img, torch.zeros(grad_img.size())) + mean), mean + mean * 0.1, 0).data / torch.max(grad_img)\n",
    "        neg_grad_img = torch.max(-grad_img, torch.zeros(grad_img.size())) / -torch.min(grad_img)\n",
    "\n",
    "        img = topil(img_tensor.squeeze(0).cpu())\n",
    "#         img.show()\n",
    "        img_name = 'img_grads/' + genres[gid] + '_'+ str(int(top_labels[gid][i])) + '_' + str(top_ids[gid][i])\n",
    "        img.save(img_name + '.png')\n",
    "        img_pos_grad = topil(pos_grad_img)\n",
    "        img_pos_grad = img_pos_grad.filter(GaussianBlur(radius=1))\n",
    "        img_pos_grad.save(img_name + '_grad.png')\n",
    "\n",
    "#         img_pos_grad.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
